{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-label text classification",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOY0YPxtjPoxnWYM35jxFiv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dankimh/BERT-multilabel-classification/blob/main/multi_label_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSvvTJPlIIge"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "!pip install pytorch_lightning\n",
        "!pip install torchmetrics\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.functional import accuracy, f1_score, auroc\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "BERT_MODEL='beomi/kcbert-base'\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "pl.seed_everything(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/smilegate-ai/korean_unsmile_dataset/main/unsmile_train_v1.0.tsv\", filename=\"unsmile_train_v1.0.tsv\")\n",
        "train_data=pd.read_table('unsmile_train_v1.0.tsv')\n",
        "#train_data=train_data.rename(columns={'문장': 'sentence', '여성/가족': 'women/family', '남성': 'men', '성소수자': 'lgbtq', '인종/국적': 'nationality', '연령': 'age', '지역': 'region', '종교': 'religion', '기타 혐오': 'hate', '악플/욕설': 'bad'})\n",
        "print(train_data.head())\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/smilegate-ai/korean_unsmile_dataset/main/unsmile_valid_v1.0.tsv\", filename=\"unsmile_valid_v1.0.tsv\")\n",
        "valid_data=pd.read_table('unsmile_valid_v1.0.tsv')\n",
        "#valid_data.head()"
      ],
      "metadata": {
        "id": "qXxXc9b8LeSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_COLUMNS=train_data.columns.tolist()[2:]\n",
        "\n",
        "train_doc_len=[len(x) for x in train_data['문장']]\n",
        "plt.subplots(constrained_layout=True)\n",
        "plt.subplot(2,1,1)\n",
        "plt.title('train',fontsize=20)\n",
        "plt.hist(train_doc_len,bins=30)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dUsnprH2bGfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n"
      ],
      "metadata": {
        "id": "rCZI_Zpz2rqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "\n",
        "    def __init__(self,data,tokenizer,max_token_len):\n",
        "        self.tokenizer=tokenizer\n",
        "        self.data=data\n",
        "        self.max_token_len=max_token_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self,index:int):\n",
        "        data_row=self.data.iloc[index]\n",
        "\n",
        "        문장=data_row.문장\n",
        "        labels=data_row[LABEL_COLUMNS]\n",
        "\n",
        "        encoding=self.tokenizer.encode_plus(문장,add_special_tokens=True,max_length=self.max_token_len,return_token_type_ids=False,padding=\"max_length\",truncation=True,return_attention_mask=True,return_tensors='pt')\n",
        "\n",
        "        return dict(문장=문장,input_ids=encoding[\"input_ids\"].flatten(),attention_mask=encoding[\"attention_mask\"].flatten(),labels=torch.FloatTensor(labels))"
      ],
      "metadata": {
        "id": "eTFQWsOn3PPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=200\n",
        "print(type(train_data))\n",
        "train_data_sample=BERTDataset(train_data,tokenizer,max_token_len=max_len)\n",
        "\n",
        "sample=train_data_sample[0]\n",
        "sample.keys()"
      ],
      "metadata": {
        "id": "qwl2X2aJ4f4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample[\"input_ids\"]"
      ],
      "metadata": {
        "id": "hQP-OS2_6VGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model=BertModel.from_pretrained(BERT_MODEL,return_dict=True)\n"
      ],
      "metadata": {
        "id": "4Qfh5sDrYNAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_batch=next(iter(DataLoader(train_data_sample,batch_size=8,num_workers=2)))\n",
        "sample_batch[\"input_ids\"].shape, sample_batch[\"attention_mask\"].shape"
      ],
      "metadata": {
        "id": "hJKFeh7caNv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=bert_model(sample_batch[\"input_ids\"],sample_batch[\"attention_mask\"])\n",
        "output.last_hidden_state.shape, output.pooler_output.shape"
      ],
      "metadata": {
        "id": "i9m_bw12cRSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HateSpeechDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self,train_df,test_df,tokenizer,batch_size=8,max_token_len=128):\n",
        "        super().__init__()\n",
        "        self.batch_size=batch_size\n",
        "        self.train_df=train_df\n",
        "        self.test_df=test_df\n",
        "        self.tokenizer=tokenizer\n",
        "        self.max_token_len=max_token_len\n",
        "\n",
        "    def setup(self,stage=None):\n",
        "        self.train_dataset=BERTDataset(self.train_df,self.tokenizer,self.max_token_len)\n",
        "\n",
        "        self.test_dataset=BERTDataset(self.test_df,self.tokenizer,self.max_token_len)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.test_dataset,batch_size=self.batch_size,num_workers=2)\n"
      ],
      "metadata": {
        "id": "04ivk8u9ct7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS=10\n",
        "BATCH_SIZE=12\n",
        "\n",
        "data_module=HateSpeechDataModule(train_data,valid_data,tokenizer,batch_size=BATCH_SIZE,max_token_len=max_len)"
      ],
      "metadata": {
        "id": "6O5s7GQifjX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HateSpeechTagger(pl.LightningModule):\n",
        "    def __init__(self,n_classes:int,n_training_steps=None,n_warmup_steps=None):\n",
        "        super().__init__()\n",
        "        self.bert=BertModel.from_pretrained(BERT_MODEL,return_dict=True)\n",
        "        self.classifier=nn.Linear(self.bert.config.hidden_size,n_classes) #models\n",
        "        self.n_training_steps=n_training_steps\n",
        "        self.n_warmup_steps=n_warmup_steps\n",
        "        self.criterion=nn.BCELoss()\n",
        "\n",
        "    def forward(self,input_ids,attention_mask,labels=None):\n",
        "        output=self.bert(input_ids,attention_mask=attention_mask)\n",
        "        output=self.classifier(output.pooler_output)\n",
        "        output=torch.sigmoid(output)\n",
        "        loss=0\n",
        "        if labels is not None:\n",
        "            loss=self.criterion(output,labels)\n",
        "        return loss,output\n",
        "\n",
        "    def training_step(self,batch,batch_idx):\n",
        "        input_ids=batch[\"input_ids\"]\n",
        "        attention_mask=batch[\"attention_mask\"]\n",
        "        labels=batch[\"labels\"]\n",
        "        loss,outputs=self(input_ids,attention_mask,labels)\n",
        "        self.log(\"train_loss\",loss,prog_bar=True,logger=True)\n",
        "        return {\"loss\":loss,\"predictions\":outputs,\"labels\":labels}\n",
        "        \n",
        "    def validation_step(self,batch,batch_idx):\n",
        "        input_ids=batch[\"input_ids\"]\n",
        "        attention_mask=batch[\"attention_mask\"]\n",
        "        labels=batch[\"labels\"]\n",
        "        loss,outputs=self(input_ids,attention_mask,labels)\n",
        "        self.log(\"val_loss\",loss,prog_bar=True,logger=True)\n",
        "        return loss\n",
        "    \n",
        "    def test_step(self,batch,batch_idx):\n",
        "        input_ids=batch[\"input_ids\"]\n",
        "        attention_mask=batch[\"attention_mask\"]\n",
        "        labels=batch[\"labels\"]\n",
        "        loss,outputs=self(input_ids,attention_mask,labels)\n",
        "        self.log(\"test_loss\",loss,prog_bar=True,logger=True)\n",
        "        return loss\n",
        "    \n",
        "    def training_epoch_end(self,outputs):\n",
        "\n",
        "        labels=[]\n",
        "        predictions=[]\n",
        "        for output in outputs:\n",
        "            for out_labels in output[\"labels\"].detach().cpu():\n",
        "                labels.append(out_labels)\n",
        "            for out_predictions in output[\"predictions\"].detach().cpu():\n",
        "                predictions.append(out_predictions)\n",
        "\n",
        "        labels=torch.stack(labels).int()\n",
        "        predictions=torch.stack(predictions)\n",
        "\n",
        "        for i, name in enumerate(LABEL_COLUMNS):\n",
        "            class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
        "            self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
        "\n",
        "        \n",
        "    def configure_optimizers(self):\n",
        "\n",
        "        optimizer=AdamW(self.parameters(),lr=2e-5)\n",
        "\n",
        "        scheduler=get_linear_schedule_with_warmup(optimizer,num_warmup_steps=self.n_warmup_steps,num_training_steps=self.n_training_steps)\n",
        "\n",
        "        return dict(optimizer=optimizer,lr_scheduler=dict(scheduler=scheduler,interval='step'))\n"
      ],
      "metadata": {
        "id": "0jFoFhvGhLCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch=len(train_data)\n",
        "total_training_steps=steps_per_epoch*N_EPOCHS"
      ],
      "metadata": {
        "id": "oZuvyWPUskna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warmup_steps=total_training_steps // 5\n",
        "warmup_steps,total_training_steps"
      ],
      "metadata": {
        "id": "i2kpmclSvCnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=HateSpeechTagger(n_classes=len(LABEL_COLUMNS),n_warmup_steps=warmup_steps,n_training_steps=total_training_steps)\n"
      ],
      "metadata": {
        "id": "eTsIG5vHvOlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback=ModelCheckpoint(dirpath=\"checkpoints\",filename=\"best-checkpoint\",save_top_k=1,verbose=True,monitor=\"val_loss\",mode=\"min\")\n"
      ],
      "metadata": {
        "id": "Dn2eKLBPwQAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger=TensorBoardLogger(\"lightning_logs\",name=\"hate-speechs\")"
      ],
      "metadata": {
        "id": "E5HGiyZMwjgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback=EarlyStopping(monitor=\"train_loss\",patience=2)"
      ],
      "metadata": {
        "id": "7BAredM7wqpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer=pl.Trainer(logger=logger,checkpoint_callback=checkpoint_callback,callbacks=[early_stopping_callback],max_epochs=N_EPOCHS,gpus=1,progress_bar_refresh_rate=30)"
      ],
      "metadata": {
        "id": "u2_1SU7hww51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model,data_module)"
      ],
      "metadata": {
        "id": "WX9te1bnyof8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer.test()"
      ],
      "metadata": {
        "id": "4b44soSMvODX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = HateSpeechTagger.load_from_checkpoint(\n",
        "  trainer.checkpoint_callback.best_model_path,\n",
        "  n_classes=len(LABEL_COLUMNS)\n",
        ")\n",
        "trained_model.eval()\n",
        "trained_model.freeze()"
      ],
      "metadata": {
        "id": "FhGAMtY-1xHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_comment = \"\"\n",
        "encoding = tokenizer.encode_plus(\n",
        "  test_comment,\n",
        "  add_special_tokens=True,\n",
        "  max_length=max_len,\n",
        "  return_token_type_ids=False,\n",
        "  padding=\"max_length\",\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")\n",
        "_, test_prediction = trained_model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
        "test_prediction = test_prediction.flatten().numpy()\n",
        "for label, prediction in zip(LABEL_COLUMNS, test_prediction):\n",
        "  print(f\"{label}: {prediction}\")"
      ],
      "metadata": {
        "id": "8PmrwvtB14Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "trained_model = trained_model.to(device)\n",
        "val_dataset = BERTDataset(\n",
        "  valid_data,\n",
        "  tokenizer,\n",
        "  max_token_len=max_len\n",
        ")\n",
        "predictions = []\n",
        "labels = []\n",
        "for item in tqdm(val_dataset):\n",
        "  _, prediction = trained_model(\n",
        "    item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
        "    item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
        "  )\n",
        "  predictions.append(prediction.flatten())\n",
        "  labels.append(item[\"labels\"].int())\n",
        "predictions = torch.stack(predictions).detach().cpu()\n",
        "labels = torch.stack(labels).detach().cpu()"
      ],
      "metadata": {
        "id": "E7yl6Dzd2MwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(predictions, labels, threshold=THRESHOLD)"
      ],
      "metadata": {
        "id": "zREZaEfP2yhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AUROC per tag\")\n",
        "for i, name in enumerate(LABEL_COLUMNS):\n",
        "  tag_auroc = auroc(predictions[:, i], labels[:, i], pos_label=1)\n",
        "  print(f\"{name}: {tag_auroc}\")"
      ],
      "metadata": {
        "id": "uuI6Z7Be22A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predictions.numpy()\n",
        "y_true = labels.numpy()\n",
        "upper, lower = 1, 0\n",
        "y_pred = np.where(y_pred > THRESHOLD, upper, lower)\n",
        "print(classification_report(\n",
        "  y_true,\n",
        "  y_pred,\n",
        "  target_names=LABEL_COLUMNS,\n",
        "  zero_division=0\n",
        "))"
      ],
      "metadata": {
        "id": "gsVo1csX24eg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}